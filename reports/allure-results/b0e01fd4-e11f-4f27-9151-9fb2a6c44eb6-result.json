{"name": "Validate AI response accuracy and semantics - faq_visa_ar", "status": "failed", "statusDetails": {"message": "AssertionError: [faq_visa_ar] similarity 0.48 facts 1/3\nassert False", "trace": "logged_in_page = <Page url='https://govgpt.sandbox.dge.gov.ae/c/9b4b1910-aaad-4af9-b14e-90bb4553fe9a'>\ncase = {'golden': 'يمكنك تجديد تأشيرة الإقامة من خلال منصات ICP أو GDRFA. تحقق من الأهلية وقدّم البيانات الحيوية إذا طُلب ذلك.', 'id': 'faq_visa_ar', 'lang': 'ar', 'must_contain': ['ICP', 'GDRFA', 'البيانات الحيوية'], ...}\n\n    @allure.epic(\"Response Accuracy and Relevance\")\n    @allure.feature(\"Response Accuracy and Relevance\")\n    @allure.story(\"Validate AI responses against golden answers and fact checks\")\n    @allure.title(\"Validate chatbot response similarity and fact coverage for all prompts - {case[id]}\")\n    @allure.description(\"\"\"\n    Objective:\n    To verify that for all prompts (English and Arabic), the AI response is similar to the golden response\n    when available, contains required factual information, and meets quality thresholds.\n    \"\"\")\n    #@pytest.mark.parametrize(\"case\", DATA.get(\"prompts\", []))\n    @pytest.mark.parametrize(\"case\", DATA.get(\"prompts\", []), ids=lambda c: c.get(\"id\", \"no-id\"))\n    def test_app_vs_golden_similarity(logged_in_page, case):\n        allure.dynamic.title(f\"Validate AI response accuracy and semantics - {case.get('id', 'no-id')}\")\n        page   = logged_in_page\n        user_q = case.get(\"user\") or case.get(\"prompt\",\"\")\n        golden = (case.get(\"golden\") or \"\").strip()  # may be empty in future\n        lang   = case.get(\"lang\",\"en\")\n        facts  = [f.lower() for f in case.get(\"must_contain\", [])]\n        base_thr = float(case.get(\"threshold\", 0.85 if lang==\"en\" else case.get(\"xl_threshold\", 0.80)))\n    \n        # Ask & capture\n        app_ans = _send_and_get_answer(page, user_q)\n    \n        # Similarity (if golden present)\n        score = None\n        if golden:\n            score = sim_xl(app_ans, golden) if lang==\"ar\" else sim_en(app_ans, golden)\n    \n        # Fact coverage\n        app_norm = _norm(app_ans)\n        hits = sum(1 for f in facts if f in app_norm) if facts else 0\n        needed = max(1, min(2, len(facts))) if facts else 0\n    \n        # Length-aware relax (only if golden exists)\n        if golden:\n            len_ratio = max(1.0, len(app_ans)/max(1,len(golden)))\n            relax = 0.10 if len_ratio >= 3.0 else (0.05 if len_ratio >= 1.8 else 0.0)\n            eff_thr = max(0.70, base_thr - relax)\n            ok = (score >= base_thr) or ((score >= eff_thr) and (hits >= needed))\n        else:\n            # No golden: require substantive answer + facts hit (when provided)\n            ok = (len(app_ans.strip()) > 50) and (hits >= needed)\n    \n        # Allure attachments\n        allure.attach(user_q, \"prompt\", allure.attachment_type.TEXT)\n        allure.attach(app_ans, \"app_answer\", allure.attachment_type.TEXT)\n        if golden:\n            allure.attach(golden, \"golden_answer\", allure.attachment_type.TEXT)\n            allure.attach(f\"{score:.3f}\", \"similarity\", allure.attachment_type.TEXT)\n            allure.attach(\n                f\"url={page.url}\\n\"\n                f\"facts_hit={hits}/{len(facts)}\\n\"\n                f\"base_thr={base_thr:.2f}\\n\"\n                f\"eff_thr={eff_thr:.2f}\\n\",\n                \"diagnostics\",\n                allure.attachment_type.TEXT\n            )\n        else:\n            allure.attach(\n                f\"url={page.url}\\n\"\n                f\"facts_hit={hits}/{len(facts)}\\n\"\n                f\"no_golden=True\\n\",\n                \"diagnostics\",\n                allure.attachment_type.TEXT\n            )\n    \n        if not ok:\n            take_screenshot(page, f\"fail_{case.get('id','case')}_fullpage\")\n            try:\n                resp_el = page.locator(\"(//div[@id='response-content-container'])[last()]\")\n                if resp_el.count():\n                    allure.attach(resp_el.screenshot(), f\"fail_{case.get('id','case')}_response\", allure.attachment_type.PNG)\n            except Exception:\n                pass\n            attach_dom(page, f\"dom_fail_{case.get('id','case')}\")\n    \n>       assert ok, (\n            f\"[{case.get('id','case')}] \"\n            + (f\"similarity {score:.2f} \" if score is not None else \"no_golden \")\n            + f\"facts {hits}/{len(facts)}\"\n        )\nE       AssertionError: [faq_visa_ar] similarity 0.48 facts 1/3\nE       assert False\n\ntests\\genai\\test_against_golden.py:97: AssertionError"}, "description": "\nObjective:\nTo verify that for all prompts (English and Arabic), the AI response is similar to the golden response\nwhen available, contains required factual information, and meets quality thresholds.\n", "attachments": [{"name": "prompt", "source": "f8c22034-f699-4303-bd98-8fda390c287a-attachment.txt", "type": "text/plain"}, {"name": "app_answer", "source": "93f2f54b-cff5-40bb-815c-1542148756bb-attachment.txt", "type": "text/plain"}, {"name": "golden_answer", "source": "84a08a4b-3ee9-4374-a3eb-c2132317e2f9-attachment.txt", "type": "text/plain"}, {"name": "similarity", "source": "3ae09503-7576-42b2-a5ee-d146b755d7c2-attachment.txt", "type": "text/plain"}, {"name": "diagnostics", "source": "46f33d59-9af4-43bd-9e05-50341e1c90c4-attachment.txt", "type": "text/plain"}, {"name": "fail_faq_visa_ar_fullpage", "source": "e340f68c-9803-4fdc-989b-2be0c09086d9-attachment.png", "type": "image/png"}, {"name": "fail_faq_visa_ar_response", "source": "928b3fea-cf7e-45a4-9fea-326bb8d4fe2f-attachment.png", "type": "image/png"}, {"name": "dom_fail_faq_visa_ar", "source": "0396bc80-9456-4742-84ff-4d65c0b91a12-attachment.html", "type": "text/html"}, {"name": "FAILED_test_app_vs_golden_similarity[faq_visa_ar]", "source": "3b730c44-7fbf-40af-82c0-830a2cf32985-attachment.png", "type": "image/png"}, {"name": "DOM_test_app_vs_golden_similarity[faq_visa_ar]", "source": "dec1fdbb-85a4-4fe9-b584-eb31632afbe9-attachment.html", "type": "text/html"}], "parameters": [{"name": "case", "value": "{'id': 'faq_visa_ar', 'lang': 'ar', 'user': 'كيف أجدد تأشيرة الإقامة في الإمارات؟', 'golden': 'يمكنك تجديد تأشيرة الإقامة من خلال منصات ICP أو GDRFA. تحقق من الأهلية وقدّم البيانات الحيوية إذا طُلب ذلك.', 'xl_threshold': 0.8, 'must_contain': ['ICP', 'GDRFA', 'البيانات الحيوية']}"}], "start": 1755618717723, "stop": 1755618765009, "uuid": "dc8543e5-587f-40e4-ba0e-c6cf059e9653", "historyId": "a98ba02307902777b29bf10a19ef84ff", "testCaseId": "4351bef7262dccc0f46b030dd9a53ecd", "fullName": "tests.genai.test_against_golden#test_app_vs_golden_similarity", "labels": [{"name": "epic", "value": "Response Accuracy and Relevance"}, {"name": "feature", "value": "Response Accuracy and Relevance"}, {"name": "story", "value": "Validate AI responses against golden answers and fact checks"}, {"name": "parentSuite", "value": "tests.genai"}, {"name": "suite", "value": "test_against_golden"}, {"name": "host", "value": "LAPTOP-ITSGITUD"}, {"name": "thread", "value": "8660-MainThread"}, {"name": "framework", "value": "pytest"}, {"name": "language", "value": "cpython3"}, {"name": "package", "value": "tests.genai.test_against_golden"}]}